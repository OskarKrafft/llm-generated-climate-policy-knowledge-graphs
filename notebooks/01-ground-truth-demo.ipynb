{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Generation Demo\n",
    "\n",
    "This notebook demonstrates how to generate ground truth RDF data from policy documents using the POLIANNA ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Add the project root to Python's path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)  # Make src importable\n",
    "\n",
    "from src.ground_truth_generation.generate_ground_truth import (\n",
    "    generate_turtle_for_article,\n",
    "    load_ontology_and_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up paths and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/oskarkrafft/Desktop/Projects/LLM-policy-knowledge-graphs/polianna-dataset/data/03b_processed_to_json\n",
      "Output directory: /Users/oskarkrafft/Desktop/Projects/LLM-policy-knowledge-graphs/polianna-processed/turtle\n",
      "Ontology path: /Users/oskarkrafft/Desktop/Projects/LLM-policy-knowledge-graphs/ontology/polianna-ontology.ttl\n"
     ]
    }
   ],
   "source": [
    "# Set paths for input and output\n",
    "data_dir = os.path.join(project_root, \"polianna-dataset\", \"data\", \"03b_processed_to_json\")\n",
    "output_dir = os.path.join(project_root, \"polianna-processed\", \"turtle\")\n",
    "ontology_path = os.path.join(project_root, \"ontology\", \"polianna-ontology.ttl\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Ontology path: {ontology_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: List available article folders and select one for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 412 article folders.\n",
      "1. EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55\n",
      "2. EU_32012L0027_Title_0_Chapter_3_Section_0_Article_14\n",
      "3. EU_32008R1099_Title_0_Chapter_0_Section_0_Article_11\n",
      "4. EU_32006L0032_Title_0_Chapter_3_Section_0_Article_07\n",
      "5. EU_32014L0094_Title_0_Chapter_0_Section_0_Article_04\n",
      "\n",
      "Selected folder for demonstration: EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55\n"
     ]
    }
   ],
   "source": [
    "# List all article folders in the data directory\n",
    "article_folders = [entry.path for entry in os.scandir(data_dir) if entry.is_dir()]\n",
    "print(f\"Found {len(article_folders)} article folders.\")\n",
    "\n",
    "# Display the first few article folders\n",
    "for i, folder in enumerate(article_folders[:5]):\n",
    "    print(f\"{i+1}. {os.path.basename(folder)}\")\n",
    "\n",
    "# Select the first folder for demonstration\n",
    "demo_folder = article_folders[0]\n",
    "print(f\"\\nSelected folder for demonstration: {os.path.basename(demo_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the content of the selected folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required files exist: True\n",
      "\n",
      "Policy Information:\n",
      "Titel: EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55\n",
      "CELEX_Number: 32019L0944\n",
      "ELI: http://data.europa.eu/eli/dir/2019/944/oj\n",
      "Annotators: ['A', 'B']\n",
      "\n",
      "Total annotations: 14\n",
      "\n",
      "First 3 annotations:\n",
      "\n",
      "Annotation 1:\n",
      "  Layer: Instrumenttypes\n",
      "  Feature: InstrumentType\n",
      "  Tag: RegulatoryInstr\n",
      "  Text: right of access to accounts...\n",
      "\n",
      "Annotation 2:\n",
      "  Layer: Instrumenttypes\n",
      "  Feature: InstrumentType\n",
      "  Tag: RegulatoryInstr\n",
      "  Text: right of access...\n",
      "\n",
      "Annotation 3:\n",
      "  Layer: Instrumenttypes\n",
      "  Feature: InstrumentType\n",
      "  Tag: RegulatoryInstr\n",
      "  Text: right of access...\n"
     ]
    }
   ],
   "source": [
    "# Check if the required files exist\n",
    "curated_path = os.path.join(demo_folder, \"Curated_Annotations.json\")\n",
    "info_path = os.path.join(demo_folder, \"Policy_Info.json\")\n",
    "text_path = os.path.join(demo_folder, \"Raw_Text.txt\")\n",
    "\n",
    "files_exist = all(os.path.isfile(p) for p in [curated_path, info_path, text_path])\n",
    "print(f\"Required files exist: {files_exist}\")\n",
    "\n",
    "# Display policy information\n",
    "with open(info_path, encoding=\"utf-8\") as f:\n",
    "    policy_info = json.load(f)\n",
    "\n",
    "print(\"\\nPolicy Information:\")\n",
    "for key, value in policy_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Display first few annotations\n",
    "with open(curated_path, encoding=\"utf-8\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "print(f\"\\nTotal annotations: {len(annotations)}\")\n",
    "print(\"\\nFirst 3 annotations:\")\n",
    "for i, ann in enumerate(annotations[:3]):\n",
    "    print(f\"\\nAnnotation {i+1}:\")\n",
    "    print(f\"  Layer: {ann.get('layer')}\")\n",
    "    print(f\"  Feature: {ann.get('feature')}\")\n",
    "    print(f\"  Tag: {ann.get('tag')}\")\n",
    "    print(f\"  Text: {ann.get('text')[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate the Turtle file for the selected article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Turtle file: /Users/oskarkrafft/Desktop/Projects/LLM-policy-knowledge-graphs/polianna-processed/turtle/EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55.ttl\n",
      "Successfully created Turtle file at: /Users/oskarkrafft/Desktop/Projects/LLM-policy-knowledge-graphs/polianna-processed/turtle/EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55.ttl\n",
      "File size: 9.40 KB\n"
     ]
    }
   ],
   "source": [
    "# Generate the Turtle file\n",
    "generate_turtle_for_article(demo_folder, output_dir)\n",
    "\n",
    "# Path to the generated Turtle file\n",
    "folder_name = os.path.basename(os.path.normpath(demo_folder))\n",
    "ttl_path = os.path.join(output_dir, f\"{folder_name}.ttl\")\n",
    "\n",
    "# Check if the file was created successfully\n",
    "if os.path.isfile(ttl_path):\n",
    "    print(f\"Successfully created Turtle file at: {ttl_path}\")\n",
    "    print(f\"File size: {os.path.getsize(ttl_path) / 1024:.2f} KB\")\n",
    "else:\n",
    "    print(f\"Failed to create Turtle file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Explore the generated Turtle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 lines of the Turtle file:\n",
      "@prefix polianna: <https://polianna-kg.org/> .\n",
      "@prefix eli: <http://data.europa.eu/eli/ontology#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<https://polianna-kg.org/data/document/32019L0944> a polianna:PolicyDocument ;\n",
      "rdfs:label \"32019L0944\" .\n",
      "\n",
      "<https://polianna-kg.org/data/article/EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55> a polianna:PolicyArticle ;\n",
      "rdfs:label \"EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55\" ;\n",
      "polianna:fullText \"article 55\\nright of access to accounts\\n1.   member states or any competent authority that they designate, including the regulatory authorities referred to in article 57, shall, insofar as necessary to carry out their functions, have right of access to the accounts of electricity undertakings as set out in article 56.\\n2.   member states and any designated competent authority, including the regulatory authorities, shall preserve the confidentiality of commercially sensitive information. member states may provide for the disclosure of such information where such disclosure is necessary in order for the competent authorities to carry out their functions.\\n\" .\n",
      "\n",
      "<https://polianna-kg.org/data/document/32019L0944> polianna:hasArticle <https://polianna-kg.org/data/article/EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55> .\n",
      "\n",
      "<https://polianna-kg.org/data/article/EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55/ann_CUR5818> a polianna:SpanAnnotation ;\n",
      "polianna:startIndex \"12\"^^xsd:integer ;\n",
      "polianna:endIndex \"39\"^^xsd:integer ;\n",
      "polianna:annotatedText \"right of access to accounts\" ;\n",
      "polianna:hasFeature polianna:InstrumentType ;\n"
     ]
    }
   ],
   "source": [
    "# Display the first few lines of the Turtle file\n",
    "with open(ttl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ttl_content = f.readlines()\n",
    "\n",
    "print(f\"First 20 lines of the Turtle file:\")\n",
    "for line in ttl_content[:20]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load the generated Turtle file into an RDF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 104 triples from the Turtle file.\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, URIRef\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "\n",
    "# Load just the generated Turtle file\n",
    "g = Graph()\n",
    "g.parse(ttl_path, format=\"turtle\")\n",
    "\n",
    "print(f\"Loaded {len(g)} triples from the Turtle file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Explore the RDF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts:\n",
      "Actor: 9\n",
      "InstrumentType: 3\n",
      "Compliance: 1\n",
      "Objective: 1\n",
      "\n",
      "Tag counts:\n",
      "RegulatoryInstr: 3\n",
      "Authority_monitoring: 3\n",
      "Addressee_default: 3\n",
      "Authority_default: 2\n",
      "Form_monitoring: 1\n",
      "Addressee_monitored: 1\n",
      "Objective_QualIntention_noCCM: 1\n"
     ]
    }
   ],
   "source": [
    "# Define namespaces\n",
    "POLIANNA = Namespace(\"https://polianna-kg.org/\")\n",
    "\n",
    "# Count occurrences of different features\n",
    "print(\"Feature counts:\")\n",
    "feature_counts = {}\n",
    "for s, p, o in g.triples((None, URIRef(POLIANNA + \"hasFeature\"), None)):\n",
    "    feature = o.split(\"#\")[-1] if \"#\" in o else o.split(\"/\")[-1]\n",
    "    feature_counts[feature] = feature_counts.get(feature, 0) + 1\n",
    "\n",
    "for feature, count in sorted(feature_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {count}\")\n",
    "\n",
    "# Count occurrences of different tags\n",
    "print(\"\\nTag counts:\")\n",
    "tag_counts = {}\n",
    "for s, p, o in g.triples((None, URIRef(POLIANNA + \"hasTag\"), None)):\n",
    "    tag = o.split(\"#\")[-1] if \"#\" in o else o.split(\"/\")[-1]\n",
    "    tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "\n",
    "for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{tag}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Run SPARQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Article Information:\n",
      "Article URI: https://polianna-kg.org/data/article/EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55\n",
      "Label: EU_32019L0944_Title_0_Chapter_6_Section_5_Article_55\n",
      "\n",
      "Snippets with Features (first 5):\n",
      "\n",
      "Text: right of access to accounts\n",
      "Feature: InstrumentType\n",
      "Tag: RegulatoryInstr\n",
      "\n",
      "Text: right of access\n",
      "Feature: InstrumentType\n",
      "Tag: RegulatoryInstr\n",
      "\n",
      "Text: right of access\n",
      "Feature: InstrumentType\n",
      "Tag: RegulatoryInstr\n",
      "\n",
      "Text: member states\n",
      "Feature: Actor\n",
      "Tag: Authority_monitoring\n",
      "\n",
      "Text: competent authority\n",
      "Feature: Actor\n",
      "Tag: Authority_monitoring\n"
     ]
    }
   ],
   "source": [
    "# Query to get policy article information\n",
    "article_query = \"\"\"\n",
    "PREFIX polianna: <https://polianna-kg.org/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?article ?label WHERE {\n",
    "    ?article a polianna:PolicyArticle ;\n",
    "             rdfs:label ?label .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Policy Article Information:\")\n",
    "for row in g.query(article_query):\n",
    "    print(f\"Article URI: {row.article}\")\n",
    "    print(f\"Label: {row.label}\")\n",
    "\n",
    "# Query to get snippet text and its feature\n",
    "snippet_query = \"\"\"\n",
    "PREFIX polianna: <https://polianna-kg.org/>\n",
    "\n",
    "SELECT ?text ?feature ?tag WHERE {\n",
    "    ?ann a polianna:SpanAnnotation ;\n",
    "         polianna:annotatedText ?text ;\n",
    "         polianna:hasFeature ?feature ;\n",
    "         polianna:hasTag ?tag .\n",
    "}\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nSnippets with Features (first 5):\")\n",
    "for row in g.query(snippet_query):\n",
    "    feature = row.feature.split(\"/\")[-1]\n",
    "    tag = row.tag.split(\"/\")[-1]\n",
    "    text = row.text[:50] + \"...\" if len(row.text) > 50 else row.text\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"Tag: {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "1. Select a policy document from the dataset\n",
    "2. Generate an RDF Turtle file using the POLIANNA ontology\n",
    "3. Load and explore the generated data using RDFLib\n",
    "4. Query the data using SPARQL\n",
    "\n",
    "The generated Turtle files can now be loaded into a triple store or used with other RDF tools for more advanced analysis and querying."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POLIANNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
